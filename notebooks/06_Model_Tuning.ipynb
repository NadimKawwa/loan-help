{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "goog_drive=False\n",
    "\n",
    "if goog_drive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    goog_dir = '/content/drive/My Drive/lending_club_project/'\n",
    "else:\n",
    "    goog_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "from utils import chunk_loader\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory to save files\n",
    "save_path = os.path.join(goog_dir, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get directory\n",
    "df_train_path = os.path.join(goog_dir, 'data/df_train_scaled.csv.zip')\n",
    "df_test_path = os.path.join(goog_dir, 'data/df_test_scaled.csv.zip')\n",
    "\n",
    "#download in chunks\n",
    "df_train = chunk_loader(df_train_path, index_col=0)\n",
    "df_test = chunk_loader(df_test_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292073, 42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11534, 42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'loan_status'\n",
    "\n",
    "#feature space\n",
    "X_train = df_train.drop(columns=[target_col]).values\n",
    "X_test = df_test.drop(columns=[target_col]).values\n",
    "\n",
    "#target variable\n",
    "y_train = df_train[target_col].values\n",
    "y_test = df_test[target_col].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 GridSearchCV + Oversampling\n",
    "In this section we will make use of an algorithm in order to oversample the minority class. This will be integrated as part of the pipeline in order to avoid leakage.\n",
    "\n",
    "For oversampling we can make use of SMOTE or the more simple RandomOverSampler. The choice of oversampling boils  down to speed and efficiency considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 30.4min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed: 52.3min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 81.7min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed: 81.8min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed: 110.1min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 136.8min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 138.3min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 156.7min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed: 165.7min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed: 185.8min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed: 188.6min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 206.6min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed: 215.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 244.1min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 272.4min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed: 290.0min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed: 292.3min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed: 301.5min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 310.5min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed: 339.8min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed: 342.1min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 350.8min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 381.3min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 411.7min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed: 414.5min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 442.2min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed: 443.7min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed: 446.2min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed: 468.7min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed: 496.6min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 497.6min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 528.5min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed: 571.5min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed: 575.4min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 604.4min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 608.3min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed: 639.4min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 643.1min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed: 671.1min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 674.6min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed: 710.8min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed: 748.4min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 786.6min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 790.7min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed: 792.0min\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  54 | elapsed: 853.9min remaining: 87.1min\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  54 | elapsed: 857.8min remaining: 50.5min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed: 1094.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('sampling',\n",
       "                                        SMOTE(k_neighbors=5, kind='deprecated',\n",
       "                                              m_neighbors='deprecated',\n",
       "                                              n_jobs=1, out_step='deprecated',\n",
       "                                              random_state=None, ratio=None,\n",
       "                                              sampling_strategy='auto',\n",
       "                                              svm_estimator='deprecated')),\n",
       "                                       ('xgb',\n",
       "                                        XGBClassifier(base_score=0.5,\n",
       "                                                      booster='gbtree',\n",
       "                                                      colsample_bylevel=1,...\n",
       "                                                      objective='binary:logistic',\n",
       "                                                      random_state=0,\n",
       "                                                      reg_alpha=0, reg_lambda=1,\n",
       "                                                      scale_pos_weight=1,\n",
       "                                                      seed=None, silent=None,\n",
       "                                                      subsample=1,\n",
       "                                                      verbosity=1))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'xgb__colsample_bytree': [0.9, 1.0],\n",
       "                         'xgb__eta': [0.05, 0.1, 0.3],\n",
       "                         'xgb__max_depth': [3, 6, 12]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the param grid\n",
    "# Parameters of pipelines can be set using ‘__’ separated para\n",
    "clf_grid = {\n",
    "    'xgb__eta': [0.05, 0.1, 0.3],\n",
    "    'xgb__max_depth': [3, 6, 12],\n",
    "    'xgb__colsample_bytree': [0.9, 1.0],\n",
    "    }\n",
    "\n",
    "#define the pipeline\n",
    "model_pipe = Pipeline([\n",
    "    ('sampling', SMOTE()),\n",
    "    ('xgb', xgb.XGBClassifier(n_estimators=200,\n",
    "                              n_jobs=-1))\n",
    "])\n",
    "\n",
    "#define the classifer\n",
    "clf = GridSearchCV(model_pipe,\n",
    "                   clf_grid,\n",
    "                   n_jobs=-1,\n",
    "                   cv=3, \n",
    "                   verbose=50, \n",
    "                   scoring='roc_auc')\n",
    "\n",
    "\n",
    "#fit to training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters: \n",
      "\n",
      "{'xgb__colsample_bytree': 0.9, 'xgb__eta': 0.3, 'xgb__max_depth': 3}\n",
      "Best model score: \n",
      "\n",
      "0.6755571785773941\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model parameters: \\n\")\n",
    "print(clf.best_params_ )\n",
    "print(\"Best model score: \\n\")\n",
    "\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Model Persistence\n",
    "We wish to demonsrate how to save and load the model for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models at: models/xgb_grid_2020-02-29.pickle\n"
     ]
    }
   ],
   "source": [
    "#define location to save trained model\n",
    "save_model_dir = os.path.join(save_path, 'xgb_grid_2020-02-29.pickle')\n",
    "print(\"Saving models at: {}\".format(save_model_dir))\n",
    "#save the model\n",
    "with open(save_model_dir, 'wb') as handle:\n",
    "    pickle.dump(clf,\n",
    "                handle,\n",
    "                protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demonstrate how to load\n",
    "with open(save_model_dir, 'rb') as handle:\n",
    "    clf_load = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
